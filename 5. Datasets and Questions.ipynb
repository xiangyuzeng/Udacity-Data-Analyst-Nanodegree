{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enron\n",
    "\n",
    "Largest case of corporate fraud in US history.\n",
    "\n",
    "'Enron corpus' is hundreds of thousands of emails. Biggest set of emails that exist in the open.\n",
    "\n",
    "Question: Any patterns within the emails of people who were persons of interest (POIs) in the fraud case.\n",
    "\n",
    "Topics:\n",
    "* Regression: Relationship between salaries and bonuses\n",
    "* Clustering (Unsupervised learning algorithm) -> Who within organisation was on the board of directors\n",
    "    * Can also identify types of users based on their movie preferences\n",
    "* Outlier detection and removal -> Detect bugs that we need to clean manually to make sure we get good results from the data\n",
    "\n",
    "Questions may not be easy to solve.\n",
    "\n",
    "### What is a person of interest?\n",
    "\n",
    "Someone who (was)\n",
    "* Indicted (charged with a crime)\n",
    "* Settled without admitting guilt (e.g. paid a fine)\n",
    "* Testified in exchange for immunity.\n",
    "\n",
    "-> Judgements as to which to include.\n",
    "\n",
    "Here had to go out and **manually** find out who should be assigned the **label** POI through newspaper articles. Total 35 POIs.\n",
    "\n",
    "-> Should be skeptical of these labels.\n",
    "\n",
    "### Accuracy <-> Training Set Size\n",
    "Q: Enough events to capture all the trends in the data?\n",
    "\n",
    "[img](images/5-03.png)\n",
    "\n",
    "Concerned if we were down in the bottom left column (training set size so small that accuracy is v low and accuracy can be increased dramatically by increasing training set size by some smallish number.)\n",
    "\n",
    "### Enron Email Dataset\n",
    "\n",
    "Q: How many POIs' emails do I have? Do we have sufficient data to discover trends in their emails?\n",
    "-> Do it manually\n",
    "-> Discovered we onl had 4-5 people we had the inboxes of. Discouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Data\n",
    "\n",
    "* numerical - numerical values (numbers)\n",
    "* categorical - limited number of discrete values (category, e.g. stars in ratings)\n",
    "* time series - temporal value (date, timestamp. e.g. in finance)\n",
    "* text - words\n",
    "\n",
    "e.g. \n",
    "* salary info - numerical \n",
    "* job title - categorical\n",
    "* timestamps on emails - time series\n",
    "* contents of emails - text\n",
    "* no. of emails sent by a given person (have to write feature ourselves) - numerical\n",
    "* to/from fields of emails - text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Project (Exploring the Enron Data) Notes\n",
    "\n",
    "This goes to say that, when generating or augmenting a dataset, you should be exceptionally careful if your data are coming from different sources for different classes. It can easily lead to the type of bias or mistake that we showed here. There are ways to deal with this, for example, you wouldn’t have to worry about this problem if you used only email data--in that case, discrepancies in the financial data wouldn’t matter because financial features aren’t being used. There are also more sophisticated ways of estimating how much of an effect these biases can have on your final answer; those are beyond the scope of this course.\n",
    "\n",
    "For now, the takeaway message is to be very careful about introducing features that come from different sources depending on the class! It’s a classic way to accidentally introduce biases and mistakes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
